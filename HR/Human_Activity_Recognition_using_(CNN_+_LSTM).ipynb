{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "bUz6PJy280my",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6580b4b3-4a52-4c7e-8f33-1eab4d87e94d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pafy in /usr/local/lib/python3.7/dist-packages (0.5.5)\n",
            "Requirement already satisfied: youtube-dl in /usr/local/lib/python3.7/dist-packages (2021.12.17)\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.7/dist-packages (0.2.3.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from moviepy) (1.21.6)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.7/dist-packages (from moviepy) (4.64.0)\n",
            "Requirement already satisfied: imageio<3.0,>=2.1.2 in /usr/local/lib/python3.7/dist-packages (from moviepy) (2.4.1)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.7/dist-packages (from moviepy) (4.4.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from imageio<3.0,>=2.1.2->moviepy) (7.1.2)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: imageio-ffmpeg in /usr/local/lib/python3.7/dist-packages (0.4.7)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: imageio==2.4.1 in /usr/local/lib/python3.7/dist-packages (2.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from imageio==2.4.1) (1.21.6)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from imageio==2.4.1) (7.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install pafy youtube-dl moviepy\n",
        "!pip install imageio-ffmpeg\n",
        "!pip3 install imageio==2.4.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "60z-yVmc9DSz"
      },
      "outputs": [],
      "source": [
        "\n",
        "import os\n",
        "import cv2\n",
        "import pafy\n",
        "import math\n",
        "import random\n",
        "import numpy as np\n",
        "import datetime as dt\n",
        "import tensorflow as tf\n",
        "from collections import deque\n",
        "import matplotlib.pyplot as plt\n",
        " \n",
        "from moviepy.editor import *\n",
        "%matplotlib inline\n",
        " \n",
        "from sklearn.model_selection import train_test_split\n",
        " \n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.utils import plot_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ZipROYd09DPN"
      },
      "outputs": [],
      "source": [
        "\n",
        "seed_constant = 27\n",
        "np.random.seed(seed_constant)\n",
        "random.seed(seed_constant)\n",
        "tf.random.set_seed(seed_constant)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wztDRsiT9DMs"
      },
      "outputs": [],
      "source": [
        "\n",
        "%%capture\n",
        " \n",
        "# Downlaod the UCF50 Dataset\n",
        "!wget --no-check-certificate https://www.crcv.ucf.edu/data/UCF50.rar\n",
        " \n",
        "#Extract the Dataset\n",
        "!unrar x UCF50.rar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rWAX8F079DKA"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize = (20, 20))\n",
        " \n",
        "\n",
        "all_classes_names = os.listdir('UCF50')\n",
        " \n",
        "\n",
        "random_range = random.sample(range(len(all_classes_names)), 20)\n",
        "\n",
        "for counter, random_index in enumerate(random_range, 1):\n",
        " \n",
        " \n",
        "    selected_class_Name = all_classes_names[random_index]\n",
        " \n",
        "    # Retrieve the list of all the video files present in the randomly selected Class Directory.\n",
        "    video_files_names_list = os.listdir(f'UCF50/{selected_class_Name}')\n",
        " \n",
        "    # Randomly select a video file from the list retrieved from the randomly selected Class Directory.\n",
        "    selected_video_file_name = random.choice(video_files_names_list)\n",
        " \n",
        "    # Initialize a VideoCapture object to read from the video File.\n",
        "    video_reader = cv2.VideoCapture(f'UCF50/{selected_class_Name}/{selected_video_file_name}')\n",
        "    \n",
        "\n",
        "    _, bgr_frame = video_reader.read()\n",
        " \n",
        "   \n",
        "    video_reader.release()\n",
        " \n",
        " \n",
        "    rgb_frame = cv2.cvtColor(bgr_frame, cv2.COLOR_BGR2RGB)\n",
        " \n",
        "   \n",
        "    cv2.putText(rgb_frame, selected_class_Name, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
        "\n",
        "    plt.subplot(5, 4, counter);plt.imshow(rgb_frame);plt.axis('off')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ousN0wBX9DHO"
      },
      "outputs": [],
      "source": [
        "\n",
        "IMAGE_HEIGHT , IMAGE_WIDTH = 64, 64\n",
        " \n",
        "\n",
        "SEQUENCE_LENGTH = 20\n",
        "\n",
        "DATASET_DIR = \"UCF50\"\n",
        "CLASSES_LIST = [\"WalkingWithDog\", \"TaiChi\", \"Swing\", \"HorseRace\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lYsIjyze9DEg"
      },
      "outputs": [],
      "source": [
        "def frames_extraction(video_path):\n",
        "    '''\n",
        "    This function will extract the required frames from a video after resizing and normalizing them.\n",
        "    Args:\n",
        "        video_path: The path of the video in the disk, whose frames are to be extracted.\n",
        "    Returns:\n",
        "        frames_list: A list containing the resized and normalized frames of the video.\n",
        "    '''\n",
        " \n",
        "    frames_list = []\n",
        "    \n",
        "    video_reader = cv2.VideoCapture(video_path)\n",
        " \n",
        "   \n",
        "    video_frames_count = int(video_reader.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        " \n",
        "    \n",
        "    skip_frames_window = max(int(video_frames_count/SEQUENCE_LENGTH), 1)\n",
        " \n",
        "  \n",
        "    for frame_counter in range(SEQUENCE_LENGTH):\n",
        " \n",
        "       \n",
        "        video_reader.set(cv2.CAP_PROP_POS_FRAMES, frame_counter * skip_frames_window)\n",
        " \n",
        " \n",
        "        success, frame = video_reader.read() \n",
        " \n",
        "    \n",
        "        if not success:\n",
        "            break\n",
        " \n",
        "       \n",
        "        resized_frame = cv2.resize(frame, (IMAGE_HEIGHT, IMAGE_WIDTH))\n",
        "      \n",
        "        normalized_frame = resized_frame / 255\n",
        "    \n",
        "        frames_list.append(normalized_frame)\n",
        "    \n",
        "\n",
        "    video_reader.release()\n",
        "\n",
        "    return frames_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HaTjO6xP9DBr"
      },
      "outputs": [],
      "source": [
        "def create_dataset():\n",
        "   \n",
        " \n",
        "\n",
        "    features = []\n",
        "    labels = []\n",
        "    video_files_paths = []\n",
        "    \n",
        "    \n",
        "    for class_index, class_name in enumerate(CLASSES_LIST):\n",
        "        \n",
        "      \n",
        "        print(f'Extracting Data of Class: {class_name}')\n",
        "        \n",
        "   \n",
        "        files_list = os.listdir(os.path.join(DATASET_DIR, class_name))\n",
        "\n",
        "        for file_name in files_list:\n",
        "            \n",
        "\n",
        "            video_file_path = os.path.join(DATASET_DIR, class_name, file_name)\n",
        " \n",
        "\n",
        "            frames = frames_extraction(video_file_path)\n",
        " \n",
        "            if len(frames) == SEQUENCE_LENGTH:\n",
        " \n",
        "                # Append the data to their repective lists.\n",
        "                features.append(frames)\n",
        "                labels.append(class_index)\n",
        "                video_files_paths.append(video_file_path)\n",
        "\n",
        "    features = np.asarray(features)\n",
        "    labels = np.array(labels)  \n",
        "\n",
        "    return features, labels, video_files_paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Upb1pIQ9C-0"
      },
      "outputs": [],
      "source": [
        "# Create the dataset.\n",
        "features, labels, video_files_paths = create_dataset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cpK-0_JO9C73"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Using Keras's to_categorical method to convert labels into one-hot-encoded vectors\n",
        "one_hot_encoded_labels = to_categorical(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pN0Zbv9R9C5c"
      },
      "outputs": [],
      "source": [
        "def create_convlstm_model():\n",
        "    '''\n",
        "    This function will construct the required convlstm model.\n",
        "    Returns:\n",
        "        model: It is the required constructed convlstm model.\n",
        "    '''\n",
        " \n",
        "    \n",
        "    model = Sequential()\n",
        " \n",
        "  \n",
        "    model.add(ConvLSTM2D(filters = 4, kernel_size = (3, 3), activation = 'tanh',data_format = \"channels_last\",\n",
        "                         recurrent_dropout=0.2, return_sequences=True, input_shape = (SEQUENCE_LENGTH,\n",
        "                                                                                      IMAGE_HEIGHT, IMAGE_WIDTH, 3)))\n",
        "    \n",
        "    model.add(MaxPooling3D(pool_size=(1, 2, 2), padding='same', data_format='channels_last'))\n",
        "    model.add(TimeDistributed(Dropout(0.2)))\n",
        "    \n",
        "    model.add(ConvLSTM2D(filters = 8, kernel_size = (3, 3), activation = 'tanh', data_format = \"channels_last\",\n",
        "                         recurrent_dropout=0.2, return_sequences=True))\n",
        "    \n",
        "    model.add(MaxPooling3D(pool_size=(1, 2, 2), padding='same', data_format='channels_last'))\n",
        "    model.add(TimeDistributed(Dropout(0.2)))\n",
        "    \n",
        "    model.add(ConvLSTM2D(filters = 14, kernel_size = (3, 3), activation = 'tanh', data_format = \"channels_last\",\n",
        "                         recurrent_dropout=0.2, return_sequences=True))\n",
        "    \n",
        "    model.add(MaxPooling3D(pool_size=(1, 2, 2), padding='same', data_format='channels_last'))\n",
        "    model.add(TimeDistributed(Dropout(0.2)))\n",
        "    \n",
        "    model.add(ConvLSTM2D(filters = 16, kernel_size = (3, 3), activation = 'tanh', data_format = \"channels_last\",\n",
        "                         recurrent_dropout=0.2, return_sequences=True))\n",
        "    \n",
        "    model.add(MaxPooling3D(pool_size=(1, 2, 2), padding='same', data_format='channels_last'))\n",
        "    #model.add(TimeDistributed(Dropout(0.2)))\n",
        "    \n",
        "    model.add(Flatten()) \n",
        "    \n",
        "    model.add(Dense(len(CLASSES_LIST), activation = \"softmax\"))\n",
        "    \n",
        "   \n",
        "    model.summary()\n",
        "    \n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iz2WpIDY9C2z"
      },
      "outputs": [],
      "source": [
        "\n",
        "convlstm_model = create_convlstm_model()\n",
        " \n",
        "\n",
        "print(\"Model Created Successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "inLcVxnV9Czz"
      },
      "outputs": [],
      "source": [
        "\n",
        "plot_model(convlstm_model, to_file = 'convlstm_model_structure_plot.png', show_shapes = True, show_layer_names = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hIDXg6mfA6nJ"
      },
      "outputs": [],
      "source": [
        "\n",
        "features_train, features_test, labels_train, labels_test = train_test_split(features, one_hot_encoded_labels, test_size = 0.25, shuffle = True, random_state = seed_constant)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "84yXdoaF9CxD"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "early_stopping_callback = EarlyStopping(monitor = 'val_loss', patience = 10, mode = 'min', restore_best_weights = True)\n",
        " \n",
        "\n",
        "convlstm_model.compile(loss = 'categorical_crossentropy', optimizer = 'Adam', metrics = [\"accuracy\"])\n",
        " \n",
        "\n",
        "convlstm_model_training_history = convlstm_model.fit(x = features_train, y = labels_train, epochs = 50, batch_size = 4,shuffle = True, validation_split = 0.2, callbacks = [early_stopping_callback])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nb24lqaq9CuZ"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Evaluate the trained model.\n",
        "model_evaluation_history = convlstm_model.evaluate(features_test, labels_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qDOjWUNS9Crp"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Get the loss and accuracy from model_evaluation_history.\n",
        "model_evaluation_loss, model_evaluation_accuracy = model_evaluation_history\n",
        " \n",
        "date_time_format = '%Y_%m_%d__%H_%M_%S'\n",
        "current_date_time_dt = dt.datetime.now()\n",
        "current_date_time_string = dt.datetime.strftime(current_date_time_dt, date_time_format)\n",
        " \n",
        "\n",
        "model_file_name = f'convlstm_model___Date_Time_{current_date_time_string}___Loss_{model_evaluation_loss}___Accuracy_{model_evaluation_accuracy}.h5'\n",
        " \n",
        "convlstm_model.save(model_file_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-aOdHYmX9Coj"
      },
      "outputs": [],
      "source": [
        "\n",
        "def plot_metric(model_training_history, metric_name_1, metric_name_2, plot_name):\n",
        "\n",
        "    # Get metric values using metric names as identifiers.\n",
        "    metric_value_1 = model_training_history.history[metric_name_1]\n",
        "    metric_value_2 = model_training_history.history[metric_name_2]\n",
        "    \n",
        "    # Construct a range object which will be used as x-axis (horizontal plane) of the graph.\n",
        "    epochs = range(len(metric_value_1))\n",
        " \n",
        "    # Plot the Graph.\n",
        "    plt.plot(epochs, metric_value_1, 'blue', label = metric_name_1)\n",
        "    plt.plot(epochs, metric_value_2, 'red', label = metric_name_2)\n",
        " \n",
        "    # Add title to the plot.\n",
        "    plt.title(str(plot_name))\n",
        " \n",
        "    # Add legend to the plot.\n",
        "    plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EpmMq2-A9CmA"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Visualize the training and validation loss metrices.\n",
        "plot_metric(convlstm_model_training_history, 'loss', 'val_loss', 'Total Loss vs Total Validation Loss')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z1g1ao-s9CjZ"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Visualize the training and validation accuracy metrices.\n",
        "plot_metric(convlstm_model_training_history, 'accuracy', 'val_accuracy', 'Total Accuracy vs Total Validation Accuracy') "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WxZKBK7u9CLz"
      },
      "outputs": [],
      "source": [
        "\n",
        "def download_youtube_videos(youtube_video_url, output_directory):\n",
        "\n",
        " \n",
        "     # Create a video object which contains useful information about the video.\n",
        "     video = pafy.new(youtube_video_url)\n",
        " \n",
        "     # Retrieve the title of the video.\n",
        "     title = video.title\n",
        " \n",
        "     # Get the best available quality object for the video.\n",
        "     video_best = video.getbest()\n",
        " \n",
        "     # Construct the output file path.\n",
        "     output_file_path = f'{output_directory}/{title}.mp4'\n",
        " \n",
        "     # Download the youtube video at the best available quality and store it to the contructed path.\n",
        "     video_best.download(filepath = output_file_path, quiet = True)\n",
        " \n",
        "     # Return the video title.\n",
        "     return title"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "faJpZ33KIxXT"
      },
      "outputs": [],
      "source": [
        "!pip install git+https://github.com/Cupcakus/pafy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TsM9E3IAMK_s"
      },
      "outputs": [],
      "source": [
        "!pip uninstall -y pafy\n",
        "!pip install git+https://github.com/Cupcakus/pafy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TgLm1v-q9CJS"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "# Make the Output directory if it does not exist\n",
        "test_videos_directory = 'test_videos'\n",
        "os.makedirs(test_videos_directory, exist_ok = True)\n",
        "\n",
        " \n",
        "# Download a YouTube Video.\n",
        "video_title = download_youtube_videos('https://www.youtube.com/watch?v=8u0qjmHIOcE', test_videos_directory)\n",
        " \n",
        "# Get the YouTube Video's path we just downloaded.\n",
        "input_video_file_path = f'{test_videos_directory}/{video_title}.mp4'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LL5vkgN09CG3"
      },
      "outputs": [],
      "source": [
        "\n",
        "def predict_on_video(video_file_path, output_file_path, SEQUENCE_LENGTH):\n",
        " \n",
        " \n",
        "    # Initialize the VideoCapture object to read from the video file.\n",
        "    video_reader = cv2.VideoCapture(video_file_path)\n",
        " \n",
        "\n",
        "    original_video_width = int(video_reader.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    original_video_height = int(video_reader.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        " \n",
        "\n",
        "    video_writer = cv2.VideoWriter(output_file_path, cv2.VideoWriter_fourcc('M', 'P', '4', 'V'), \n",
        "                                   video_reader.get(cv2.CAP_PROP_FPS), (original_video_width, original_video_height))\n",
        " \n",
        "\n",
        "    frames_queue = deque(maxlen = SEQUENCE_LENGTH)\n",
        " \n",
        "    predicted_class_name = ''\n",
        " \n",
        "    # Iterate until the video is accessed successfully.\n",
        "    while video_reader.isOpened():\n",
        " \n",
        "        # Read the frame.\n",
        "        ok, frame = video_reader.read() \n",
        "        \n",
        "        if not ok:\n",
        "            break\n",
        "\n",
        "        resized_frame = cv2.resize(frame, (IMAGE_HEIGHT, IMAGE_WIDTH))\n",
        "        \n",
        "\n",
        "        normalized_frame = resized_frame / 255\n",
        " \n",
        "       \n",
        "        frames_queue.append(normalized_frame)\n",
        " \n",
        "        if len(frames_queue) == SEQUENCE_LENGTH:\n",
        " \n",
        "\n",
        "            predicted_labels_probabilities = convlstm_model.predict(np.expand_dims(frames_queue, axis = 0))[0]\n",
        " \n",
        "            # Get the index of class with highest probability.\n",
        "            predicted_label = np.argmax(predicted_labels_probabilities)\n",
        " \n",
        "            # Get the class name using the retrieved index.\n",
        "            predicted_class_name = CLASSES_LIST[predicted_label]\n",
        " \n",
        "      \n",
        "        cv2.putText(frame, predicted_class_name, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
        " \n",
        "     \n",
        "        video_writer.write(frame)\n",
        "        \n",
        "    video_reader.release()\n",
        "    video_writer.release()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "giaVioFT9CEP"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Construct the output video path.\n",
        "output_video_file_path = f'{test_videos_directory}/{video_title}-Output-SeqLen{SEQUENCE_LENGTH}.mp4'\n",
        " \n",
        "# Perform Action Recognition on the Test Video.\n",
        "predict_on_video(input_video_file_path, output_video_file_path, SEQUENCE_LENGTH)\n",
        " \n",
        "# Display the output video.\n",
        "VideoFileClip(output_video_file_path, audio=False, target_resolution=(300,None)).ipython_display()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "73B_nGxh9B8o"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ui7P0RwX9B6D"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TaSvLSCn9B3a"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DZrqHr8f9BzD"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HRortYke9Bt_"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Human Activity Recognition using (CNN + LSTM).ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}